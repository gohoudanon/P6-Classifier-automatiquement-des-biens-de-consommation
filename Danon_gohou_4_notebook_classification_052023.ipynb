{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97e33f31",
   "metadata": {},
   "source": [
    "#  P6 : Classifiez automatiquement des biens de consommation¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28954ae",
   "metadata": {},
   "source": [
    "# Classiffication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94139b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-12 17:58:01.276091: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import os\n",
    "from os import listdir\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from glob import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D \n",
    "from tensorflow.keras.layers import GlobalAveragePooling1D \n",
    "from tensorflow.keras.layers import Flatten \n",
    "from tensorflow.keras.layers import Dense \n",
    "from tensorflow.keras.layers import Dropout \n",
    "from tensorflow.keras.layers import Rescaling\n",
    "from tensorflow.keras.layers import RandomFlip\n",
    "from tensorflow.keras.layers import RandomRotation\n",
    "from tensorflow.keras.layers import RandomZoom\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5ba265",
   "metadata": {},
   "source": [
    "## Étape 0 : Division du dataset en train et test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1dcbed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Chargement du jeu de données\n",
    "df = pd.read_csv('flipkart_com-ecommerce_sample_1050.csv')\n",
    "# Ajout variable images\n",
    "path_images = '/Users/danongohou/Desktop/P6/Images/'\n",
    "\n",
    "# Ajout de nouvelles variables \n",
    "df['label_name'] = df['product_category_tree'].apply(lambda x: x.split('>>')[0][2:].strip().replace('&', 'and'))\n",
    "df['image_path'] = [path_images + row for row in df['image']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9756afc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1050, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = df[['image','image_path', 'label_name']]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59c6c819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label_name\n",
       "Home Furnishing                 150\n",
       "Baby Care                       150\n",
       "Watches                         150\n",
       "Home Decor and Festive Needs    150\n",
       "Kitchen and Dining              150\n",
       "Beauty and Personal Care        150\n",
       "Computers                       150\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label_name'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c792454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>image_path</th>\n",
       "      <th>label_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55b85ea15a1536d46b7190ad6fff8ce7.jpg</td>\n",
       "      <td>/Users/danongohou/Desktop/P6/Images/55b85ea15a...</td>\n",
       "      <td>Home Furnishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7b72c92c2f6c40268628ec5f14c6d590.jpg</td>\n",
       "      <td>/Users/danongohou/Desktop/P6/Images/7b72c92c2f...</td>\n",
       "      <td>Baby Care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64d5d4a258243731dc7bbb1eef49ad74.jpg</td>\n",
       "      <td>/Users/danongohou/Desktop/P6/Images/64d5d4a258...</td>\n",
       "      <td>Baby Care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d4684dcdc759dd9cdf41504698d737d8.jpg</td>\n",
       "      <td>/Users/danongohou/Desktop/P6/Images/d4684dcdc7...</td>\n",
       "      <td>Home Furnishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6325b6870c54cd47be6ebfbffa620ec7.jpg</td>\n",
       "      <td>/Users/danongohou/Desktop/P6/Images/6325b6870c...</td>\n",
       "      <td>Home Furnishing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  image   \n",
       "0  55b85ea15a1536d46b7190ad6fff8ce7.jpg  \\\n",
       "1  7b72c92c2f6c40268628ec5f14c6d590.jpg   \n",
       "2  64d5d4a258243731dc7bbb1eef49ad74.jpg   \n",
       "3  d4684dcdc759dd9cdf41504698d737d8.jpg   \n",
       "4  6325b6870c54cd47be6ebfbffa620ec7.jpg   \n",
       "\n",
       "                                          image_path       label_name  \n",
       "0  /Users/danongohou/Desktop/P6/Images/55b85ea15a...  Home Furnishing  \n",
       "1  /Users/danongohou/Desktop/P6/Images/7b72c92c2f...        Baby Care  \n",
       "2  /Users/danongohou/Desktop/P6/Images/64d5d4a258...        Baby Care  \n",
       "3  /Users/danongohou/Desktop/P6/Images/d4684dcdc7...  Home Furnishing  \n",
       "4  /Users/danongohou/Desktop/P6/Images/6325b6870c...  Home Furnishing  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.copy()\n",
    "data.to_csv(\"data_cls.csv\", index=False)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ae0c773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image_path\n",
       "/Users/danongohou/Desktop/P6/Images/55b85ea15a1536d46b7190ad6fff8ce7.jpg    1\n",
       "/Users/danongohou/Desktop/P6/Images/55195de3873fffaa9e37b041533d7305.jpg    1\n",
       "/Users/danongohou/Desktop/P6/Images/c65fa0b38ab99792630468bd7dd26416.jpg    1\n",
       "/Users/danongohou/Desktop/P6/Images/142994b421c052a6193052c6c8c3d076.jpg    1\n",
       "/Users/danongohou/Desktop/P6/Images/c6adf41cd378b1f6a7ac62675b060411.jpg    1\n",
       "                                                                           ..\n",
       "/Users/danongohou/Desktop/P6/Images/26989e846c2096a5b59b59cbea2cc7ab.jpg    1\n",
       "/Users/danongohou/Desktop/P6/Images/9a02f44389bda4c60e7dc23947dbca58.jpg    1\n",
       "/Users/danongohou/Desktop/P6/Images/79b78739b0ae84780001fec304ce036c.jpg    1\n",
       "/Users/danongohou/Desktop/P6/Images/91e22428c0dd8871288ba5dac35a7382.jpg    1\n",
       "/Users/danongohou/Desktop/P6/Images/f2f027ad6a6df617c9f125173da71e44.jpg    1\n",
       "Name: count, Length: 1050, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.image_path.value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cff62ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label_name\n",
       "Home Furnishing                 150\n",
       "Baby Care                       150\n",
       "Watches                         150\n",
       "Home Decor and Festive Needs    150\n",
       "Kitchen and Dining              150\n",
       "Beauty and Personal Care        150\n",
       "Computers                       150\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.label_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77a1c191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "# Dossier train data\n",
    "base_dir = '/Users/danongohou/Desktop/P6/train_val_test_datasets/'\n",
    "os.mkdir(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4715b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Vérifier si les dossiers existent, sinon les créer\n",
    "if not os.path.exists('train_set'):\n",
    "    os.makedirs('train_set')\n",
    "if not os.path.exists('test'):\n",
    "    os.makedirs('test_set') \n",
    "\n",
    "# Charger les données\n",
    "df = pd.read_csv('data_cls.csv')\n",
    "df.image_path = df['image_path']\n",
    "df.label_name = df['label_name']\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "train_data, test_data =  train_test_split(df, test_size=0.2, stratify=df.label_name, random_state=42)\n",
    "\n",
    "# Sauvegarder les datasets dans les dossiers appropriés\n",
    "train_data.to_csv('train_set/train_data.csv', index=False)\n",
    "test_data.to_csv('test_set/test_data.csv', index=False)\n",
    "\n",
    "print('train_data : ', train_data.shape[0])\n",
    "print('test_data : ', test_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef9430fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder les datasets dans les dossiers appropriés\n",
    "train_data.to_csv('train_set/train_data.csv', index=False)\n",
    "test_data.to_csv('test_set/test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "08d6767f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data :  840\n",
      "test_data :  210\n"
     ]
    }
   ],
   "source": [
    "print('train_data : ', train_data.shape[0])\n",
    "print('test_data : ', test_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac8f1f87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>image_path</th>\n",
       "      <th>label_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>5188dd28a627807407d93549580afb74.jpg</td>\n",
       "      <td>/Users/danongohou/Desktop/P6/Images/5188dd28a6...</td>\n",
       "      <td>Home Furnishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>a43fbae655e5d13215b9dd65339fa9d4.jpg</td>\n",
       "      <td>/Users/danongohou/Desktop/P6/Images/a43fbae655...</td>\n",
       "      <td>Computers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>6b043b37c38f081d96886acb5acfbdf5.jpg</td>\n",
       "      <td>/Users/danongohou/Desktop/P6/Images/6b043b37c3...</td>\n",
       "      <td>Kitchen and Dining</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>7fd12776e6d62da6e1dd3cbc9882ee5f.jpg</td>\n",
       "      <td>/Users/danongohou/Desktop/P6/Images/7fd12776e6...</td>\n",
       "      <td>Computers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>d06bb04b096c77dc3302eaf2db336f96.jpg</td>\n",
       "      <td>/Users/danongohou/Desktop/P6/Images/d06bb04b09...</td>\n",
       "      <td>Baby Care</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    image   \n",
       "799  5188dd28a627807407d93549580afb74.jpg  \\\n",
       "324  a43fbae655e5d13215b9dd65339fa9d4.jpg   \n",
       "173  6b043b37c38f081d96886acb5acfbdf5.jpg   \n",
       "391  7fd12776e6d62da6e1dd3cbc9882ee5f.jpg   \n",
       "670  d06bb04b096c77dc3302eaf2db336f96.jpg   \n",
       "\n",
       "                                            image_path          label_name  \n",
       "799  /Users/danongohou/Desktop/P6/Images/5188dd28a6...     Home Furnishing  \n",
       "324  /Users/danongohou/Desktop/P6/Images/a43fbae655...           Computers  \n",
       "173  /Users/danongohou/Desktop/P6/Images/6b043b37c3...  Kitchen and Dining  \n",
       "391  /Users/danongohou/Desktop/P6/Images/7fd12776e6...           Computers  \n",
       "670  /Users/danongohou/Desktop/P6/Images/d06bb04b09...           Baby Care  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99b39ab",
   "metadata": {},
   "source": [
    "## Étape 0 : Division du dataset en train et test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "178e8b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Chemin du dossier contenant les images\n",
    "image_folder = '/Users/danongohou/Desktop/P6/Images/'\n",
    "\n",
    "# Vérifier si les dossiers existent, sinon les créer\n",
    "if not os.path.exists('train_set'):\n",
    "    os.makedirs('train_set')\n",
    "if not os.path.exists('test_set'):\n",
    "    os.makedirs('test_set')\n",
    "\n",
    "# Liste des noms de fichiers des images\n",
    "image_files = os.listdir(image_folder)\n",
    "\n",
    "# Diviser les données en données d'entraînement et de test\n",
    "train_files, test_files = train_test_split(image_files, test_size=0.2)\n",
    "\n",
    "# Sauvegarder les images d'entraînement\n",
    "for filename in train_files:\n",
    "    source_path = os.path.join(image_folder, filename)\n",
    "    destination_path = os.path.join('train_set', filename)\n",
    "    image = Image.open(source_path)\n",
    "    image.save(destination_path)\n",
    "\n",
    "# Sauvegarder les images de test\n",
    "for filename in test_files:\n",
    "    source_path = os.path.join(image_folder, filename)\n",
    "    destination_path = os.path.join('test_set', filename)\n",
    "    image = Image.open(source_path)\n",
    "    image.save(destination_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3d9031",
   "metadata": {},
   "source": [
    "## Verification de la division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "066fe556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'images dans le dossier d'entraînement :  840\n",
      "Nombre d'images dans le dossier de test :  210\n"
     ]
    }
   ],
   "source": [
    "train_folder = './train_set'  # Dossier d'entraînement contenant les images\n",
    "test_folder = './test_set'    # Dossier de test contenant les images\n",
    "\n",
    "\n",
    "# Compter le nombre d'images dans le dossier d'entraînement\n",
    "train_image_names = os.listdir(train_folder)\n",
    "num_train_images = len(train_image_names)\n",
    "\n",
    "# Compter le nombre d'images dans le dossier de test\n",
    "test_image_names = os.listdir(test_folder)\n",
    "num_test_images = len(test_image_names)\n",
    "\n",
    "print(\"Nombre d'images dans le dossier d'entraînement : \", num_train_images)\n",
    "print(\"Nombre d'images dans le dossier de test : \", num_test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fa4929",
   "metadata": {},
   "source": [
    "## Étape 1 : Augmentation du train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "27460afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "image_dir = './train_set/'\n",
    "label_file = 'train_labels/train_lab.csv'\n",
    "\n",
    "labels = pd.read_csv(label_file)\n",
    "image_paths = []\n",
    "image_labels = []\n",
    "\n",
    "# Get a list of image files\n",
    "image_files = [filename for filename in os.listdir(image_dir) if filename.endswith('.jpg')]\n",
    "\n",
    "for filename in image_files:\n",
    "    image_path = os.path.join(image_dir, filename)\n",
    "    filename_without_extension = os.path.splitext(filename)[0]\n",
    "    label_mask = labels['image_name'] == filename\n",
    "    if label_mask.any():\n",
    "        label = labels.loc[label_mask, 'label_name'].values[0]\n",
    "        image_paths.append(image_path)\n",
    "        image_labels.append(label)\n",
    "\n",
    "# Verify the results\n",
    "for image_path, label in zip(image_paths, image_labels):\n",
    "    print(image_path, label)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c0d406",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "2e4793c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "If using all scalar values, you must pass an index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[138], line 35\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data_flow\n\u001b[1;32m     27\u001b[0m datagen \u001b[38;5;241m=\u001b[39m ImageDataGenerator(\n\u001b[1;32m     28\u001b[0m     rotation_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[1;32m     29\u001b[0m     width_shift_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m     validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m,\n\u001b[1;32m     33\u001b[0m     preprocessing_function\u001b[38;5;241m=\u001b[39mpreprocess_input)\n\u001b[0;32m---> 35\u001b[0m train_flow \u001b[38;5;241m=\u001b[39m \u001b[43mdata_flow_fct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatagen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtraining\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m val_flow \u001b[38;5;241m=\u001b[39m data_flow_fct(image_paths, labels, datagen, data_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     37\u001b[0m test_flow \u001b[38;5;241m=\u001b[39m data_flow_fct(test_data, labels, datagen, data_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[138], line 16\u001b[0m, in \u001b[0;36mdata_flow_fct\u001b[0;34m(image_paths, labels, datagen, data_type)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdata_flow_fct\u001b[39m(image_paths, labels, datagen, data_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# Create a DataFrame from the image paths and labels\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage_path\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     data \u001b[38;5;241m=\u001b[39m shuffle(data)  \u001b[38;5;66;03m# Shuffle the data if necessary\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     data_flow \u001b[38;5;241m=\u001b[39m datagen\u001b[38;5;241m.\u001b[39mflow_from_dataframe(data, directory\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     20\u001b[0m                                              x_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_path\u001b[39m\u001b[38;5;124m'\u001b[39m, y_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel_name\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     21\u001b[0m                                              weight_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m),\n\u001b[1;32m     22\u001b[0m                                              classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, class_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     23\u001b[0m                                              batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m,\n\u001b[1;32m     24\u001b[0m                                              subset\u001b[38;5;241m=\u001b[39mdata_type)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/danon/lib/python3.9/site-packages/pandas/core/frame.py:708\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    702\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    703\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    704\u001b[0m     )\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 708\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    710\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/danon/lib/python3.9/site-packages/pandas/core/internals/construction.py:481\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    478\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    479\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 481\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/danon/lib/python3.9/site-packages/pandas/core/internals/construction.py:115\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 115\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    117\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/danon/lib/python3.9/site-packages/pandas/core/internals/construction.py:645\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPer-column arrays must each be 1-dimensional\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    644\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m indexes \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m raw_lengths:\n\u001b[0;32m--> 645\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf using all scalar values, you must pass an index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_series:\n\u001b[1;32m    648\u001b[0m     index \u001b[38;5;241m=\u001b[39m union_indexes(indexes)\n",
      "\u001b[0;31mValueError\u001b[0m: If using all scalar values, you must pass an index"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "\n",
    "image_paths = './train_set/'\n",
    "labels = pd.read_csv('train_labels/train_lab.csv')\n",
    "\n",
    "batch_size = 32  # Define the batch size\n",
    "\n",
    "def data_flow_fct(image_paths, labels, datagen, data_type=None):\n",
    "    \n",
    "    data_flow = datagen.flow_from_dataframe(data, directory='',\n",
    "                                             x_col='image_path', y_col='label_name',\n",
    "                                             weight_col=None, target_size=(224, 224),\n",
    "                                             classes=None, class_mode='categorical',\n",
    "                                             batch_size=batch_size, shuffle=True, seed=42,\n",
    "                                             subset=data_type)\n",
    "    return data_flow\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.25,\n",
    "    preprocessing_function=preprocess_input)\n",
    "\n",
    "train_flow = data_flow_fct(image_paths, labels, datagen, data_type='training')\n",
    "val_flow = data_flow_fct(image_paths, labels, datagen, data_type='validation')\n",
    "test_flow = data_flow_fct(test_data, labels, datagen, data_type=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8a308448",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "64cc37a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "840\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(len(image_paths))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0880cd",
   "metadata": {},
   "source": [
    "## Étape 2 : Preprocess du train data augmenté"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155306f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "# Chemin vers le dossier d'entrée contenant les images\n",
    "input_path = './train_set'\n",
    "\n",
    "# Chemin vers le dossier de sortie\n",
    "output_path = './train_set_Processed/'\n",
    "\n",
    "# Créer le dossier de sortie s'il n'existe pas\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "# Parcourir toutes les images dans le dossier d'entrée\n",
    "for filename in os.listdir(input_path):\n",
    "    # Vérifier si le fichier est une image\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "        \n",
    "        # Charger l'image avec OpenCV\n",
    "        image = cv2.imread(os.path.join(input_path, filename))\n",
    "\n",
    "        # Correction de l'exposition avec PILS\n",
    "        image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        image = ImageOps.autocontrast(image)\n",
    "        image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Conversion en niveau de gris de l'image\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Equalization de l'histogramme de l'image\n",
    "        image = cv2.equalizeHist(image)\n",
    "        \n",
    "        # Correction du contraste \n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(3,3))\n",
    "        image = clahe.apply(image)\n",
    "    \n",
    "        # Réduction de bruit avec OpenCV\n",
    "        image = cv2.fastNlMeansDenoising(image, h=10)\n",
    "    \n",
    "        # Ajout de BLUR avec OpenCV\n",
    "        image = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "        \n",
    "        # Réduction de dimension avec OpenCV\n",
    "        image = cv2.resize(image, (224, 224))\n",
    "        \n",
    "        # Enregistrer l'image prétraitée dans le dossier de sortie\n",
    "        output_filename = os.path.splitext(filename)[0] + '.jpg'\n",
    "        output_file_path = os.path.join(output_path, output_filename)\n",
    "        cv2.imwrite(output_file_path, image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082f65b5",
   "metadata": {},
   "source": [
    "## Étape 3 : Validation Croisée sur le Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dbde09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Répertoire contenant les images d'entraînement\n",
    "train_directory = './train_set/'\n",
    "\n",
    "# Liste pour stocker les chemins d'accès aux images\n",
    "image_paths = []\n",
    "\n",
    "# Parcourir les fichiers dans le répertoire d'entraînement et ajouter les chemins d'accès aux images\n",
    "for filename in os.listdir(train_directory):\n",
    "    if filename.endswith(\".jpg\"):  # Vérifier l'extension de fichier appropriée\n",
    "        image_path = os.path.join(train_directory, filename)\n",
    "        image_paths.append(image_path)\n",
    "\n",
    "\n",
    "\n",
    "### Validation croisée k = 5\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "train_val_indices = [(train_idx, val_idx) for train_idx, val_idx in kf.split(image_paths)]\n",
    "\n",
    "val_accs = []\n",
    "test_accs = []\n",
    "\n",
    "for fold, (train_indices, val_indices) in enumerate(train_val_indices):\n",
    "    print(f'Fold {fold+1}/{5}')\n",
    "\n",
    "    # Obtenir les chemins d'accès aux images pour le fold\n",
    "    train_image_paths = [image_paths[i] for i in train_indices]\n",
    "    val_image_paths = [image_paths[i] for i in val_indices]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae75426d",
   "metadata": {},
   "source": [
    "## Étape 4 : Entrainement du modèle sur Train Data augmenté"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a108d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création du modèle\n",
    "with tf.device('/gpu:0'): \n",
    "    model = create_model_fct()\n",
    "\n",
    "# Création du callback\n",
    "model_save_path = f\"./model_fold{fold+1}_best_weights.h5\"\n",
    "checkpoint = ModelCheckpoint(model_save_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "callbacks_list = [checkpoint, es]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0435b083",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d2eb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'): \n",
    "    history = model.fit(train_flow,\n",
    "                        validation_data=val_flow,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=50,\n",
    "                        callbacks=callbacks_list,\n",
    "                        verbose=1)\n",
    "        \n",
    "# Enregistrer les données de l'entraînement pour tracer les graphes\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "train_acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23532cda",
   "metadata": {},
   "source": [
    "## Étape 5 : Évaluation du modèle sur Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a287db",
   "metadata": {},
   "outputs": [],
   "source": [
    "### évaluation du modèle\n",
    "# Score du dernier epoch\n",
    "loss, accuracy = model.evaluate(train_flow, verbose=True)\n",
    "print(\"Training Accuracy   : {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(val_flow, verbose=True)\n",
    "print(\"Validation Accuracy :  {:.4f}\".format(accuracy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4594e61",
   "metadata": {},
   "source": [
    "## Étape 6 : Évaluation du modèle sur Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faf0930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score de l'epoch optimal\n",
    "model.load_weights(model_save_path)\n",
    "loss, val_accuracy = model.evaluate(val_flow, verbose=False)\n",
    "print(\"Validation Accuracy :  {:.4f}\".format(val_accuracy))\n",
    "loss, test_accuracy = model.evaluate(test_flow, verbose=False)\n",
    "print(\"Test Accuracy       :  {:.4f}\".format(test_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f0afd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_accs.append(val_accuracy)\n",
    "test_accs.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230f63ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Average validation accuracy over {k} folds: {np.mean(val_accs)}')\n",
    "print(f'Average test accuracy over {k} folds: {np.mean(test_accs)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf53bd9",
   "metadata": {},
   "source": [
    "## Étape 7 : Graphique Loss et Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ed8b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracer les graphes de Loss et d'Accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(train_acc)\n",
    "plt.plot(val_acc)\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2527296b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
