{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97e33f31",
   "metadata": {},
   "source": [
    "#  P6 : Classifiez automatiquement des biens de consommation¶"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28954ae",
   "metadata": {},
   "source": [
    "# Classiffication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94139b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 16:50:20.296668: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import os\n",
    "from os import listdir\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from glob import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D \n",
    "from tensorflow.keras.layers import GlobalAveragePooling1D \n",
    "from tensorflow.keras.layers import Flatten \n",
    "from tensorflow.keras.layers import Dense \n",
    "from tensorflow.keras.layers import Dropout \n",
    "from tensorflow.keras.layers import Rescaling\n",
    "from tensorflow.keras.layers import RandomFlip\n",
    "from tensorflow.keras.layers import RandomRotation\n",
    "from tensorflow.keras.layers import RandomZoom\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed53502",
   "metadata": {},
   "source": [
    "- ### Données de base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "27825d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "# Chemin vers le dossier d'entrée contenant les images\n",
    "input_path = '/Users/danongohou/Desktop/P6/Images/'\n",
    "\n",
    "# Chemin vers le dossier de sortie\n",
    "output_path = '/Users/danongohou/Desktop/P6/Processed_Img_Class/'\n",
    "\n",
    "# Créer le dossier de sortie s'il n'existe pas\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "# Parcourir toutes les images dans le dossier d'entrée\n",
    "for filename in os.listdir(input_path):\n",
    "    # Vérifier si le fichier est une image\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "        \n",
    "        # Charger l'image avec OpenCV\n",
    "        image = cv2.imread(os.path.join(input_path, filename))\n",
    "\n",
    "        # Correction de l'exposition avec PILS\n",
    "        image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        image = ImageOps.autocontrast(image)\n",
    "        image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Conversion en niveau de gris de l'image\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Equalization de l'histogramme de l'image\n",
    "        image = cv2.equalizeHist(image)\n",
    "        \n",
    "        # Correction du contraste \n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(3,3))\n",
    "        image = clahe.apply(image)\n",
    "    \n",
    "        # Réduction de bruit avec OpenCV\n",
    "        image = cv2.fastNlMeansDenoising(image, h=10)\n",
    "    \n",
    "        # Ajout de BLUR avec OpenCV\n",
    "        image = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "        \n",
    "        # Réduction de dimension avec OpenCV\n",
    "        image = cv2.resize(image, (224, 224))\n",
    "        \n",
    "        # Enregistrer l'image prétraitée dans le dossier de sortie\n",
    "        output_filename = os.path.splitext(filename)[0] + '.jpg'\n",
    "        output_file_path = os.path.join(output_path, output_filename)\n",
    "        cv2.imwrite(output_file_path, image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c823fe30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./Processed_Img_Class/55b85ea15a1536d46b7190ad...</td>\n",
       "      <td>Home Furnishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./Processed_Img_Class/7b72c92c2f6c40268628ec5f...</td>\n",
       "      <td>Baby Care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./Processed_Img_Class/64d5d4a258243731dc7bbb1e...</td>\n",
       "      <td>Baby Care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./Processed_Img_Class/d4684dcdc759dd9cdf415046...</td>\n",
       "      <td>Home Furnishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./Processed_Img_Class/6325b6870c54cd47be6ebfbf...</td>\n",
       "      <td>Home Furnishing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_path       label_name\n",
       "0  ./Processed_Img_Class/55b85ea15a1536d46b7190ad...  Home Furnishing\n",
       "1  ./Processed_Img_Class/7b72c92c2f6c40268628ec5f...        Baby Care\n",
       "2  ./Processed_Img_Class/64d5d4a258243731dc7bbb1e...        Baby Care\n",
       "3  ./Processed_Img_Class/d4684dcdc759dd9cdf415046...  Home Furnishing\n",
       "4  ./Processed_Img_Class/6325b6870c54cd47be6ebfbf...  Home Furnishing"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chargement du jeu de données\n",
    "df = pd.read_csv('flipkart_com-ecommerce_sample_1050.csv')\n",
    "\n",
    "# Ajout variable images\n",
    "image_path = './Processed_Img_Class/'\n",
    "df['image_path'] = [image_path + row for row in df['image']]\n",
    "\n",
    "# Ajout de la variable  Categorie\n",
    "df['label_name'] = df['product_category_tree'].apply(lambda x: x.split('>>')[0][2:].strip())\n",
    "\n",
    "df = df[['image_path', 'label_name']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62be3178",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5ba265",
   "metadata": {},
   "source": [
    "- ### Division du dataset en train et test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "178e8b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions du DataFrame train_df : (840, 2)\n",
      "Dimensions du DataFrame test_df : (210, 2)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Vérifier si les dossiers existent sinon les créer\n",
    "if not os.path.exists('train_data'):\n",
    "    os.makedirs('train_data')\n",
    "if not os.path.exists('test_data'):\n",
    "    os.makedirs('test_data')\n",
    "\n",
    "# Charger le fichier CSV en tant que DataFrame\n",
    "data = pd.read_csv('df.csv')\n",
    "\n",
    "# Diviser les données en données d'entraînement et de test\n",
    "train_data, test_data = train_test_split(data, test_size=0.2)\n",
    "\n",
    "# Enregistrer les données d'entraînement et de test dans des fichiers CSV\n",
    "train_data.to_csv('train_data/train.csv', index=False)\n",
    "test_data.to_csv('test_data/test.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "# Charger le fichier train.csv en tant que DataFrame en excluant la première colonne\n",
    "train_df = pd.read_csv('train_data/train.csv', usecols=lambda col: col != 'Unnamed: 0')\n",
    "# Charger le fichier test.csv en tant que DataFrame en excluant la première colonne\n",
    "test_df = pd.read_csv('test_data/test.csv', usecols=lambda col: col != 'Unnamed: 0')\n",
    "\n",
    "# Afficher les dimensions du DataFrame train_df\n",
    "print('Dimensions du DataFrame train_df :', train_df.shape)\n",
    "# Afficher les dimensions du DataFrame test_df\n",
    "print('Dimensions du DataFrame test_df :', test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0311766d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./Processed_Img_Class/3d8222014ec36292c1c143c5...</td>\n",
       "      <td>Kitchen &amp; Dining</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./Processed_Img_Class/46e6853da6b0c796b7a0d820...</td>\n",
       "      <td>Home Decor &amp; Festive Needs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./Processed_Img_Class/f1484a63c0dc79e96c98b2a2...</td>\n",
       "      <td>Kitchen &amp; Dining</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./Processed_Img_Class/dbb55b8da8c30cb67014d814...</td>\n",
       "      <td>Beauty and Personal Care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./Processed_Img_Class/3ee79b1e51c9f9262e8373ce...</td>\n",
       "      <td>Beauty and Personal Care</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_path   \n",
       "0  ./Processed_Img_Class/3d8222014ec36292c1c143c5...  \\\n",
       "1  ./Processed_Img_Class/46e6853da6b0c796b7a0d820...   \n",
       "2  ./Processed_Img_Class/f1484a63c0dc79e96c98b2a2...   \n",
       "3  ./Processed_Img_Class/dbb55b8da8c30cb67014d814...   \n",
       "4  ./Processed_Img_Class/3ee79b1e51c9f9262e8373ce...   \n",
       "\n",
       "                   label_name  \n",
       "0            Kitchen & Dining  \n",
       "1  Home Decor & Festive Needs  \n",
       "2            Kitchen & Dining  \n",
       "3    Beauty and Personal Care  \n",
       "4    Beauty and Personal Care  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "359e02c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./Processed_Img_Class/2e3586dc60df258c5478446d...</td>\n",
       "      <td>Home Decor &amp; Festive Needs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./Processed_Img_Class/b454f9f449c9dff58b90113b...</td>\n",
       "      <td>Baby Care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./Processed_Img_Class/7956d9586de3e25ff586bca5...</td>\n",
       "      <td>Kitchen &amp; Dining</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./Processed_Img_Class/2cbad7ead8eb8dd92823b9f5...</td>\n",
       "      <td>Watches</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./Processed_Img_Class/e15195f2a5ebaa2168ccd653...</td>\n",
       "      <td>Watches</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_path   \n",
       "0  ./Processed_Img_Class/2e3586dc60df258c5478446d...  \\\n",
       "1  ./Processed_Img_Class/b454f9f449c9dff58b90113b...   \n",
       "2  ./Processed_Img_Class/7956d9586de3e25ff586bca5...   \n",
       "3  ./Processed_Img_Class/2cbad7ead8eb8dd92823b9f5...   \n",
       "4  ./Processed_Img_Class/e15195f2a5ebaa2168ccd653...   \n",
       "\n",
       "                   label_name  \n",
       "0  Home Decor & Festive Needs  \n",
       "1                   Baby Care  \n",
       "2            Kitchen & Dining  \n",
       "3                     Watches  \n",
       "4                     Watches  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b28d06",
   "metadata": {},
   "source": [
    "- ### Processing train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "991d4e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 179)\t1.0\n",
      "  (1, 214)\t1.0\n",
      "  (2, 783)\t1.0\n",
      "  (3, 714)\t1.0\n",
      "  (4, 183)\t1.0\n",
      "  (5, 516)\t1.0\n",
      "  (6, 73)\t1.0\n",
      "  (7, 646)\t1.0\n",
      "  (8, 0)\t1.0\n",
      "  (9, 75)\t1.0\n",
      "  (10, 711)\t1.0\n",
      "  (11, 423)\t1.0\n",
      "  (12, 386)\t1.0\n",
      "  (13, 297)\t1.0\n",
      "  (14, 458)\t1.0\n",
      "  (15, 789)\t1.0\n",
      "  (16, 801)\t1.0\n",
      "  (17, 164)\t1.0\n",
      "  (18, 459)\t1.0\n",
      "  (19, 127)\t1.0\n",
      "  (20, 436)\t1.0\n",
      "  (21, 762)\t1.0\n",
      "  (22, 682)\t1.0\n",
      "  (23, 775)\t1.0\n",
      "  (24, 549)\t1.0\n",
      "  :\t:\n",
      "  (815, 744)\t1.0\n",
      "  (816, 482)\t1.0\n",
      "  (817, 330)\t1.0\n",
      "  (818, 147)\t1.0\n",
      "  (819, 428)\t1.0\n",
      "  (820, 780)\t1.0\n",
      "  (821, 741)\t1.0\n",
      "  (822, 821)\t1.0\n",
      "  (823, 345)\t1.0\n",
      "  (824, 413)\t1.0\n",
      "  (825, 314)\t1.0\n",
      "  (826, 165)\t1.0\n",
      "  (827, 610)\t1.0\n",
      "  (828, 339)\t1.0\n",
      "  (829, 148)\t1.0\n",
      "  (830, 185)\t1.0\n",
      "  (831, 504)\t1.0\n",
      "  (832, 611)\t1.0\n",
      "  (833, 302)\t1.0\n",
      "  (834, 693)\t1.0\n",
      "  (835, 550)\t1.0\n",
      "  (836, 687)\t1.0\n",
      "  (837, 566)\t1.0\n",
      "  (838, 808)\t1.0\n",
      "  (839, 396)\t1.0\n",
      "0                Kitchen & Dining\n",
      "1      Home Decor & Festive Needs\n",
      "2                Kitchen & Dining\n",
      "3        Beauty and Personal Care\n",
      "4        Beauty and Personal Care\n",
      "                  ...            \n",
      "835               Home Furnishing\n",
      "836                       Watches\n",
      "837              Kitchen & Dining\n",
      "838               Home Furnishing\n",
      "839                     Baby Care\n",
      "Name: label_name, Length: 840, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Charger les données\n",
    "train_df = pd.read_csv('train_data/train.csv', usecols=lambda col: col != 'Unnamed: 0')\n",
    "\n",
    "# Séparer la variable cible des caractéristiques\n",
    "X = train_df.drop('label_name', axis=1)\n",
    "y = train_df['label_name']\n",
    "\n",
    "# Standardiser les caractéristiques numériques\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "numeric_transformer = StandardScaler()\n",
    "\n",
    "# Encoder les caractéristiques catégorielles\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Créer le préprocesseur de colonnes\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Appliquer le préprocesseur sur les caractéristiques\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Vérifier le résultat\n",
    "print(X_processed)\n",
    "print(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729820f1",
   "metadata": {},
   "source": [
    "# Classification supervisée "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ac4059",
   "metadata": {},
   "source": [
    "## Création du modèle pré-entrainé Resnet152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72764b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_fct():\n",
    "    # Récupération modèle pré-entraîné\n",
    "    base_model = ResNet152(include_top=False, weights=\"imagenet\", input_shape=(224, 224, 3))\n",
    "  \n",
    "    # Layers non entraînables - on garde les poids du modèle pré-entraîné\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Récupérer la sortie de ce réseau\n",
    "    x = base_model.output\n",
    "    # Compléter le modèle\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(4, activation='softmax')(x)\n",
    "\n",
    "    # Définir le nouveau modèle\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    # Compilation du modèle \n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer='rmsprop', metrics=[\"accuracy\"])\n",
    "\n",
    "    print(model.summary())\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be99ff5",
   "metadata": {},
   "source": [
    "## Entraînement et évaluation du modèle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca7beea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "# Lecture des fichiers CSV\n",
    "train_data = pd.read_csv('train_data/train_csv')\n",
    "test_data = pd.read_csv('test_data/test_csv')\n",
    "\n",
    "batch_size = 32\n",
    "k = 5\n",
    "\n",
    "### Création des générateurs de données\n",
    "def data_flow_fct(data, datagen, data_type=None) :\n",
    "    data_flow = datagen.flow_from_dataframe(data, directory='',\n",
    "                                x_col='image_path', y_col='label_names',\n",
    "                                weight_col=None, target_size=(256, 256),\n",
    "                                classes=None, class_mode='categorical',\n",
    "                                batch_size=batch_size, shuffle=True, seed=42,\n",
    "                                subset=data_type\n",
    "                                )\n",
    "    return data_flow\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.25,\n",
    "    preprocessing_function=preprocess_input)\n",
    "\n",
    "### Validation croisée k = 5\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "train_val_indices = [(train_idx, val_idx) for train_idx, val_idx in kf.split(train_data)]\n",
    "\n",
    "val_accs = []\n",
    "test_accs = []\n",
    "\n",
    "for fold, (train_indices, val_indices) in enumerate(train_val_indices):\n",
    "    print(f'Fold {fold+1}/{k}')\n",
    "\n",
    "    train_data_fold = train_data.iloc[train_indices]\n",
    "    val_data_fold = train_data.iloc[val_indices]\n",
    "\n",
    "    train_flow = data_flow_fct(train_data_fold, datagen, data_type='training')\n",
    "    val_flow = data_flow_fct(val_data_fold, datagen, data_type='validation')\n",
    "    test_flow = data_flow_fct(test_data, datagen, data_type=None)\n",
    "\n",
    "    # Création du modèle\n",
    "    with tf.device('/gpu:0'): \n",
    "        model = create_model_fct()\n",
    "\n",
    "    # Création du callback\n",
    "    model_save_path = f\"./model_fold{fold+1}_best_weights.h5\"\n",
    "    checkpoint = ModelCheckpoint(model_save_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "    callbacks_list = [checkpoint, es]\n",
    "\n",
    "    print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "    with tf.device('/gpu:0'): \n",
    "        history = model.fit(train_flow,\n",
    "                            validation_data=val_flow,\n",
    "                            batch_size=batch_size, \n",
    "                            epochs=50, \n",
    "                            callbacks=callbacks_list, \n",
    "                            verbose=1)\n",
    "        \n",
    "    # Enregistrer les données de l'entraînement pour tracer les graphes\n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    train_acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    \n",
    "        \n",
    "    ### évaluation du modèle\n",
    "    # Score du dernier epoch\n",
    "    loss, accuracy = model.evaluate(train_flow, verbose=True)\n",
    "    print(\"Training Accuracy   : {:.4f}\".format(accuracy))\n",
    "    loss, accuracy = model.evaluate(val_flow, verbose=True)\n",
    "    print(\"Validation Accuracy :  {:.4f}\".format(accuracy))\n",
    "\n",
    "    # Score de l'epoch optimal\n",
    "    model.load_weights(model_save_path)\n",
    "    loss, val_accuracy = model.evaluate(val_flow, verbose=False)\n",
    "    print(\"Validation Accuracy :  {:.4f}\".format(val_accuracy))\n",
    "    loss, test_accuracy = model.evaluate(test_flow, verbose=False)\n",
    "    print(\"Test Accuracy       :  {:.4f}\".format(test_accuracy))\n",
    "\n",
    "    val_accs.append(val_accuracy)\n",
    "    test_accs.append(test_accuracy)\n",
    "\n",
    "print(f'Average validation accuracy over {k} folds: {np.mean(val_accs)}')\n",
    "print(f'Average test accuracy over {k} folds: {np.mean(test_accs)}')\n",
    "\n",
    "# Tracer les graphes de Loss et d'Accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(train_acc)\n",
    "plt.plot(val_acc)\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa13a57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c35de4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
